{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = pd.read_csv('amazon_cells_labelled.txt', delimiter='\\t', \\\n",
    "                       header=None, names=['commentz', 'sentiment'])\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "data_set['words'] = data_set.commentz.str.strip().str.split('[\\W_]+')\n",
    "replace = {'\\.':' ','\\,':' ','\\!':' ','\\?':' '}\n",
    "data_set['commentz'].replace(replace,inplace=True,regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = list()\n",
    "for row in data_set[['sentiment', 'words']].iterrows():\n",
    "    r = row[1]\n",
    "    for word in r.words:\n",
    "        rows.append((r.sentiment, word))\n",
    "\n",
    "words = pd.DataFrame(rows, columns=['sentiment', 'word'])\n",
    "words = words[words.word.str.len() > 0]\n",
    "words['word'] = words.word.str.lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = words.groupby('sentiment')\\\n",
    "    .word.value_counts()\\\n",
    "    .to_frame()\\\n",
    "    .rename(columns={'word':'n_w'})\n",
    "#counts.sort_values(by='n_w', ascending=False)\n",
    "word_sum = counts.groupby(level=0)\\\n",
    "    .sum()\\\n",
    "    .rename(columns={'n_w': 'n_d'})\n",
    "tf = counts.join(word_sum)\n",
    "\n",
    "tf['tf'] = tf.n_w/tf.n_d\n",
    "tf.reset_index(drop=False, inplace=True, col_level=0, col_fill='')\n",
    "#stop_words = set(stopwords.words('english'))\n",
    "parts = ['e','t','r','o','a','s','i','d','m','he','re','ve','ll']\n",
    "tf = tf[~tf['word'].isin(parts)]\n",
    "tf[tf['sentiment']==1].sort_values(by='tf', ascending=False)\n",
    "keywords=['great','good','excellent','nice','very','best','recommend']\n",
    "all_data_set = data_set\n",
    "\n",
    "all_keywords = tf[tf['sentiment']==1]['word'].tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['good' 'excellent' 'nice' 'very' 'best' 'recommend'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-434dd674ca13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mcol_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdata_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdata_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hit'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdata_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rgorh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2680\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2681\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2682\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2683\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2684\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rgorh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2724\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2725\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2726\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2727\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rgorh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[0;32m   1325\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[1;32m-> 1327\u001b[1;33m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[0;32m   1328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['good' 'excellent' 'nice' 'very' 'best' 'recommend'] not in index\""
     ]
    }
   ],
   "source": [
    "for key in keywords:\n",
    "    col_list = keywords\n",
    "    data_set[key] = 0\n",
    "    data_set['hit'] = data_set[col_list].sum(axis=1)\n",
    "    np.where(data_set['hit']<2,\\\n",
    "             np.where(data_set.commentz.str.contains(key,case=False),1,0),0)\n",
    "\n",
    "data_set\n",
    "       \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for all_key in all_keywords:\n",
    "    all_data_set[all_key] = all_data_set.commentz.str.contains(all_key,case=False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set['sentiment_bool'] = (data_set['sentiment'] == 1)\n",
    "data = data_set[keywords]\n",
    "target = data_set['sentiment_bool']\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(data, target)\n",
    "y_pred = bnb.predict(data)\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw = list(keywords)\n",
    "scores = dict()\n",
    "\n",
    "for key in kw:\n",
    "    scores.update({key:[data_set[(data_set[key]==1)\\\n",
    "            &(data_set['sentiment']==1)][key].count(),\\\n",
    "                        data_set[(data_set[key]==1)\\\n",
    "           &(data_set['sentiment']==0)][key].count(),\\\n",
    "                       data_set[(data_set[key]==0)\\\n",
    "           &(data_set['sentiment']==1)][key].count(),\\\n",
    "                       data_set[(data_set[key]==0)\\\n",
    "           &(data_set['sentiment']==0)][key].count()]})\n",
    "\n",
    "tp = pd.DataFrame.from_dict(scores, orient='index')\n",
    "tp.reset_index(inplace=True)\n",
    "tp.rename({'index':'key_word',0:'true_pos',1:'false_neg',\\\n",
    "          2:'false_pos',3:'true_neg',4:'hit'},axis=1,inplace=True)\n",
    "tp.sort_values(['true_pos'],ascending=False,inplace=True)\n",
    "\n",
    "tp['perc'] = tp['true_pos'] / (tp['true_pos'] + tp['false_pos'])\n",
    "tp['acc'] = (tp['true_pos'] + tp['true_neg']) / (tp['true_pos'] + tp['false_pos'] \\\n",
    "                                            + tp['false_neg'] + tp['true_neg'])\n",
    "\n",
    "tp['f'] = 2 / ((1/tp['perc']) + (1/tp['true_pos']))\n",
    "\n",
    "\n",
    "tp['tp_rate'] = tp['true_pos'] / (tp['true_pos'] + tp['false_neg'])\n",
    "tp['fp_rate'] = tp['false_pos'] / (tp['false_pos'] + tp['true_neg'])\n",
    "\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(tp.fp_rate,tp.tp_rate,label='model')\n",
    "plt.plot([0,1],[0,1],'b--', label='chance')\n",
    "plt.title('Lift Curve\\nAmazon Customer Reviews')\n",
    "plt.xlabel('False Negative Rate\\n(1-specificity)')\n",
    "plt.xlim(0,1)\n",
    "plt.ylabel('True Positive Rate\\n(Sensitivity)')\n",
    "plt.ylim(0,1)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_kw = list(all_keywords)\n",
    "all_scores = dict()\n",
    "\n",
    "for key in all_kw:\n",
    "    all_scores.update({key:[all_data_set[(all_data_set[key]==True)\\\n",
    "           &(all_data_set['sentiment']==1)][key].count(),\\\n",
    "                        all_data_set[(all_data_set[key]==True)\\\n",
    "           &(all_data_set['sentiment']==0)][key].count(),\n",
    "                       all_data_set[(all_data_set[key]==False)\\\n",
    "           &(all_data_set['sentiment']==1)][key].count(),\n",
    "                       all_data_set[(all_data_set[key]==False)\\\n",
    "           &(all_data_set['sentiment']==0)][key].count()]})\n",
    "\n",
    "all_tp = pd.DataFrame.from_dict(all_scores, orient='index')\n",
    "all_tp.reset_index(inplace=True)\n",
    "all_tp.rename({'index':'key_word',0:'true_pos',1:'false_pos',\\\n",
    "          2:'false_neg',3:'true_neg'},axis=1,inplace=True)\n",
    "all_tp.sort_values(['true_pos','false_pos'],inplace=True)\n",
    "all_tp['cum_tp'] = all_tp['true_pos'].cumsum()\n",
    "all_tp['cum_fp'] = all_tp['false_pos'].cumsum()\n",
    "all_tp['cum_fn'] = all_tp['false_neg'].cumsum()\n",
    "all_tp['cum_tn'] = all_tp['true_neg'].cumsum()\n",
    "\n",
    "all_tp['perc'] = all_tp['cum_tp'] / (all_tp['cum_tp'] + all_tp['cum_fp'])\n",
    "all_tp['acc'] = (all_tp['cum_tp'] + all_tp['cum_tn']) / (all_tp['cum_tp'] + all_tp['cum_fp'] \\\n",
    "                                            + all_tp['cum_fn'] + all_tp['cum_tn'])\n",
    "all_tp['tp_rate'] = all_tp['cum_tp'] / (all_tp['cum_tp'] + all_tp['cum_fn'])\n",
    "all_tp['fp_rate'] = all_tp['cum_fp'] / (all_tp['cum_fp'] + all_tp['cum_tn'])\n",
    "all_tp['f'] = 2 / ((1/all_tp['perc']) + (1/all_tp['cum_tp']))\n",
    "\n",
    "\n",
    "all_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(all_tp.fpr_cum,all_tp.tpr_cum,label='model')\n",
    "plt.plot([0,1],[0,1],'b--', label='chance')\n",
    "plt.title('Lift Curve\\nAmazon Customer Reviews')\n",
    "plt.xlabel('False Negative Rate\\n(1-specificity)')\n",
    "plt.xlim(0,1)\n",
    "plt.ylabel('True Positive Rate\\n(Sensitivity)')\n",
    "plt.ylim(0,1)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
